<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenConstruction — Updates</title>
    <link>https://www.openconstruction.org/</link>
    <description>Newest datasets and models from OpenConstruction</description>
    <language>en-US</language>

  <item>
    <title><![CDATA[Dataset: Roadway Worker Trajectory and Context Data from VR Simulator]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=smart-safety-trajectory</link>
    <guid isPermaLink="false">datasets:smart-safety-trajectory:2026-02-04</guid>
    <pubDate>Wed, 04 Feb 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Behavioral modelling of roadway construction workers: Improving deep learning-based trajectory prediction with contextual information in traffic work zones]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:smart-safety-trajectory:2026-02-04</guid>
    <pubDate>Wed, 04 Feb 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[Construction workers face rising risks of fatal injuries from vehicle crashes in roadway work zones. While transportation safety research has focused on motorists’ behavior, the behavior of roadway workers remains underexplored. Existing trajectory prediction models, developed for pedestrians or generic construction workers, typically do not account for the unique roadway work zone activities and traffic interactions faced by roadway workers. This study leverages a virtual reality (VR) and traffic simulation-based platform to capture detailed context data, such as roadwork activities and nearby vehicles in the worker’s field of view. The study’s main objective is to evaluate whether including this context improves trajectory prediction accuracy of deep learning-based models, particularly gated recurrent units (GRU) and transformer architectures. Results indicate that transformers can improve their trajectory prediction accuracy (i.e., lower miss-rate) when accounting for both the worker’s behavioral and traffic context data compared to a transformer trained on trajectory position data alone. These improvements in accuracy are observed across different roadwork construction tasks (e.g., installing sensor cable, distributing grout) and different proximities to traffic vehicles. These findings contribute to the development of more precise roadway worker trajectory models for use in autonomous vehicles and safety systems.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: xView2 Baseline: Localization and Classification Models for Building Damage Assessment]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:xView2_baseline:2026-01-30</guid>
    <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[We present xBD, a new, large-scale dataset for the advancement of change detection and building damage assessment for humanitarian assistance and disaster recovery research. Natural disaster response requires an accurate understanding of damaged buildings in an affected region. Current response strategies require in-person damage assessments within 24-48 hours of a disaster. Massive potential exists for using aerial imagery combined with computer vision algorithms to assess damage and reduce the potential danger to human life. In collaboration with multiple disaster response agencies, xBD provides pre- and post-event satellite imagery across a variety of disaster events with building polygons, ordinal labels of damage level, and corresponding satellite metadata. Furthermore, the dataset contains bounding boxes and labels for environmental factors such as fire, water, and smoke. xBD is the largest building damage assessment dataset to date, containing 850,736 building annotations across 45,362 km	extsuperscript{2} of imagery.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Domain-adaptive instance segmentation for far-field object monitoring using SAM-based weak supervision and noisy student self-training]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:Weak_and_Self-supervision_model:2026-01-30</guid>
    <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[Automating construction site monitoring through deep learning–based segmentation presents challenges due to the high cost of pixel-wise annotations. This paper introduces a weakly and self-supervised learning framework that enhances segmentation accuracy while reducing annotation burden. Human-annotated bounding-box ground truth is used as prompts for the Segment Anything Model (SAM) to generate high-quality polygon mask labels, which are further refined through self-training. Compared to fully supervised learning models, the framework integrates Transfer Learning, Pseudo-Label Refinement, and the Noisy Student technique, improving mask mean Average Precision (Mask mAP) by 3–63% across seven target domains and achieving a Mask mAP of 72.27%. The approach also outperforms existing weakly supervised techniques, including BoxSnake and BoxTeacher, by 18% and 25.95%, respectively, and exceeds the performance of point-based methods such as PointWSSIS by 48.78%.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: xBD: A Dataset for Assessing Building Damage from Satellite Imagery]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=xBD</link>
    <guid isPermaLink="false">datasets:xBD:2026-01-29</guid>
    <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Construction Site Safety Dataset]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=Weak_and_Self_supervision</link>
    <guid isPermaLink="false">datasets:Weak_and_Self_supervision:2026-01-29</guid>
    <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: MACO: Material Counting in Construction]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=MACO</link>
    <guid isPermaLink="false">datasets:MACO:2026-01-29</guid>
    <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: OLBDA: Object-Level Building Damage Assessment Dataset]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=BDAChat</link>
    <guid isPermaLink="false">datasets:BDAChat:2026-01-20</guid>
    <pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: BDAChat: Temporal Vision-Language Model for Object-Level Building Damage Assessment]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:BDAChat:2026-01-20</guid>
    <pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[The rapid assessment of constructed facilities after extreme events is a knowledge-intensive task critical for effective emergency management. However, methodologies for automated, object-level damage assessment at scale remain underdeveloped, often lacking fine-grained interpretability or scalability. This paper introduces a framework that integrates instance segmentation with temporal Vision Language Model (VLM), which is empowered with visual damage reasoning capabilities through fine-tuning on domain-specific knowledge, for the automated and interpretable assessment of structural assets from satellite imagery. Our three-stage approach synergizes: high-precision segmentation via a modified Segment Anything Model (SAM); spatiotemporal data pairing to isolate asset-specific changes; and BDAChat, the first temporal VLM fine-tuned for object-level damage assessment. Unlike traditional black-box models, BDAChat provides both high-accuracy damage classification and causal interpretations, serving as an intelligent damage inference system. The framework’s effectiveness and scalability are validated through the Lahaina wildfire and hurricane Ian case study. This modular framework automates and accelerates the object-level building damage assessment process, demonstrating significant potential for real-time building damage evaluation and resilient infrastructure planning. The code and dataset are available at https://github.com/WangYong921/BDAChat.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Construction classification system database]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=CCS-ResourceUse</link>
    <guid isPermaLink="false">datasets:CCS-ResourceUse:2026-01-17</guid>
    <pubDate>Sat, 17 Jan 2026 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>
  </channel>
</rss>
