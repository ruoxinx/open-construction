<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenConstruction — Updates</title>
    <link>https://www.openconstruction.org/</link>
    <description>Newest datasets and models from OpenConstruction</description>
    <language>en-US</language>

  <item>
    <title><![CDATA[Model: Automated image-based generation of finite element models for masonry buildings]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:FEM_buildings:2025-11-17</guid>
    <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[To predict the response of masonry buildings to various types of loads, engineers use finite element models, specifically solid-element and macro-element models. For predicting masonry responses to seismic events in particular, equivalent frame models—a subcategory of macro-element models—are a common choice because of their low computational cost. However, an existing bottleneck in modeling pipelines is generating the geometry of the model, which is currently a slow and laborious process that is done manually using computer-aided design tools. In this paper, we address this by automating the modelling process using recent advancements in computer vision and machine learning. We present an image-based end-to-end pipeline that automatically generates finite element meshes for solid-element and equivalent-frame models of the outer walls of free-standing historical masonry buildings. As the input, our framework requires RGB images of the buildings that are processed using structure-from-motion algorithms, which create 3D geometries, and convolutional neural networks, which segment the openings and their corners. These layers are then combined to generate level of detail models. We tested our pipeline on structures with irregular surface geometries and opening layouts. While generating the solid element mesh from the level of detail model is straightforward, generating equivalent frame models required algorithms for segmenting the façade and the meshing. Experts in the field analyzed the generated equivalent frame models and determined them to be useful for numerical modeling. These finite element geometries will be invaluable for future predictions of the seismic response of damaged and undamaged buildings. The codes and dataset are publicly available for future studies and benchmarking (https://github.com/eesd-epfl/FEM_buildings and https://doi.org/10.5281/zenodo.8094306).]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Dataset for continuity-preserving crack detection]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=TOPO-Loss-Crack</link>
    <guid isPermaLink="false">datasets:TOPO-Loss-Crack:2025-11-16</guid>
    <pubDate>Sun, 16 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: TOPO-Loss for continuity-preserving crack detection using deep learning]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:topo_crack_detection:2025-11-16</guid>
    <pubDate>Sun, 16 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[We present a method for segmenting cracks in images of masonry buildings damaged by earthquakes. Existing methods of crack detection fail to preserve the continuity of cracks, and their performance deteriorates with imprecise training labels. We address these problems by adapting an approach previously proposed for reconstructing roads in aerial images, in which a Convolutional Neural Network is trained with a loss function specifically designed to encourage the continuity of thin structures and to accommodate imprecise annotations. We evaluate combinations of three loss functions (the Mean Squared Error, the Dice loss and the new connectivity-oriented loss) on two datasets using TernausNet, a deep network shown to attain state-of-the-art accuracy in crack detection. We herein show that combining these three losses significantly improves the topology of the predictions quantitatively and qualitatively. We also propose a new continuity metric, named Cracks Per Patch (CPP), and share a new dataset of images of earthquake-affected urban scenes accompanied by crack annotations. The dataset and implementations are publicly available for future studies and benchmarking (https://github.com/eesd-epfl/topo_crack_detection and https://doi.org/10.5281/zenodo.6769028).]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Determining crack kinematics from imaged crack patterns]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:crack_kinematics:2025-11-15</guid>
    <pubDate>Sat, 15 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Determining the relationship between the cause of damage and the subsequent structural behavior of infrastructure systems requires an accurate characterization of the propagation of cracks, which represents the evolution of the damage state. When no information about the cause of damage is available, kinematic approaches can be used to describe the motion of crack contours. Current image-based approaches to derive crack kinematics use digital image correlation (DIC) on a set of sequential images as the crack propagates. However, DIC is invasive in that the structure surfaces must be painted with random speckle patterns, limiting its use primarily to controlled experiments. In this paper, we propose a novel image-based methodology for computing crack opening in Mode I or Mode II. As an input, this method takes a binary image from a semantic segmentation of an image of a crack pattern. This binary image is used to detect the opposite edges along the crack, which are then registered using an optimization algorithm based on the Euclidean transformation model and non-linear least squares. As a final output, this method produces displacement maps in the tangential and normal directions to the crack skeleton. To demonstrate its performance, we validate our methodology first with synthetic crack patterns and then with real crack patterns. Because this methodology for determining crack openings requires only simple data (just a binary crack pattern image), it is straightforward, robust, and adaptable, thus contributing to the development of structural image-based damage assessments. The computational codes and datasets are available to the public for future research and benchmarking on]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Damage-augmented digital twins towards the automated inspection of buildings]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:dadt-buildings-model:2025-11-14</guid>
    <pubDate>Fri, 14 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Current procedures for the rapid inspection of buildings and infrastructure are subjective, time-consuming, and cumbersome to document, necessitating new technologies to automate the process and eliminate these shortcomings. Fortunately, recent developments in imaging devices and artificial intelligence, such as computer vision, provide the necessary tools for this, though they are not yet integrated into infrastructure applications. In this paper, we propose an end-to-end pipeline that generates damage-augmented digital twins for buildings at LOD3, including geometrical information as well as data pertaining to damage condition and its characterization. Our framework incorporates multiple-view images to (1) create a level of detail model, (2) segment damage information, and (3) characterize damage. The core of the method is the structure from motion, which is used to reconstruct the building scene, and machine-learning models that segment and characterize damage. In contrast to current practices, our method does not require manual intervention, generates lightweight models, and can be applied to a wide range of assets. The results generated with our pipeline represent a significant step towards an automated infrastructure damage assessment. We intend to expand our work in the future to include real-time applications and applications to other types of infrastructure. Codes and data sets are publicly available (https://github.com/eesd-epfl/DADT_buildings and https://doi.org/10.5281/zenodo.7767478).]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Dataset for generating LOD3 building models from SfM and semantic segmentation]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=Opening-Segmentation</link>
    <guid isPermaLink="false">datasets:Opening-Segmentation:2025-11-13</guid>
    <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Generating LOD3 building models from structure-from-motion and semantic segmentation]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:LOD3:2025-11-13</guid>
    <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[This paper describes a pipeline for automatically generating level of detail (LOD) models (digital twins), specifically LOD2 and LOD3, from free-standing buildings. Our approach combines structure from motion (SfM) with deep-learning-based segmentation techniques. Given multiple-view images of a building, we compute a three-dimensional (3D) planar abstraction (LOD2 model) of its point cloud using SfM techniques. To obtain LOD3 models, we use deep learning to perform semantic segmentation of the openings in the two-dimensional (2D) images. Unlike existing approaches, we do not rely on complex input, pre-defined 3D shapes or manual intervention. To demonstrate the robustness of our method, we show that it can generate 3D building shapes from a collection of building images with no further input. For evaluating reconstructions, we also propose two novel metrics. The first is a Euclidean–distance-based correlation of the 3D building model with the point cloud. The second involves re-projecting 3D model facades onto source photos to determine dice scores with respect to the ground-truth masks. Finally, we make the code, the image datasets, SfM outputs, and digital twins reported in this work publicly available in github.com/eesd-epfl/LOD3_buildings and doi.org/10.5281/zenodo.6651663. With this work we aim to contribute research in applications such as construction management, city planning, and mechanical analysis, among others.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Integrating extended reality and AI-based damage segmentation for near real-time, traceable bridge inspections]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:DamageSegmentationXR:2025-11-13</guid>
    <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[This paper presents a framework for interactive and traceable visual bridge inspections by integrating AI-driven image processing models with extended reality. The framework addresses the subjectivity, labor intensity, and documentation challenges of traditional visual inspections. It employs YOLO11-seg models on a mixed reality device to perform multi-class damage instance detection and segmentation in near real-time, identifying cracks, spalling, rust, efflorescence, and exposed rebar. Unlike existing methods, this approach supports automated operation and local processing without cloud computing reliance. AI predictions are embedded in the 3D extended reality environment, enhancing efficiency and accuracy while enabling inspectors to visualize and interact with damage data, improving decision-making and traceability throughout the bridge life-cycle. Beyond model’s accuracy, inference time was evaluated to verify near real-time feasibility. Tests in three real-world scenarios demonstrated practical applicability. Future work will incorporate damage characterization and decision-support tools to advance digital inspection practices and foster efficient, resilient bridge monitoring.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: CAMHighways: The Cambridge Highways Dataset]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=camhighways</link>
    <guid isPermaLink="false">datasets:camhighways:2025-11-11</guid>
    <pubDate>Tue, 11 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: TLSynth: A Novel Blender Add-On for Real-Time Point Cloud Generation from 3D Models]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:TLSynth:2025-11-11</guid>
    <pubDate>Tue, 11 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Point clouds are a crucial element in the process of scanning and reconstructing 3D environments, such as buildings or heritage sites. They allow for the creation of 3D models that can be used in a wide range of applications. In some cases, however, only the 3D model of an environment is available, and it is necessary to obtain point clouds with the same characteristics as those captured by a laser scanner. For instance, point clouds may be required for surveys, performance optimization, site scan planning, or validation of point cloud processing algorithms. This paper presents a new terrestrial laser scanner (TLS) simulator, designed as a Blender add-on, that produces synthetic point clouds from 3D models in real time. The simulator allows users to adjust a set of parameters to replicate real-world scanning conditions, such as noise generation, ensuring the synthetic point clouds closely mirror those produced by actual laser scanners. The target meshes may be derived from either a real-world scan or 3D designs created using design software. By replicating the spatial distributions and attributes of real laser scanner outputs and supporting real-time generation, the simulator serves as a valuable tool for scan planning and the development of synthetic point cloud repositories, advancing research and practical applications in 3D computer vision.]]></description>
  </item>
  </channel>
</rss>
