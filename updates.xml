<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenConstruction — Updates</title>
    <link>https://www.openconstruction.org/</link>
    <description>Newest datasets and models from OpenConstruction</description>
    <language>en-US</language>

  <item>
    <title><![CDATA[Dataset: VideoCAD: Learning Long-Horizon 3D CAD UI Interactions from Video]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=VideoCAD</link>
    <guid isPermaLink="false">datasets:VideoCAD:2025-11-26</guid>
    <pubDate>Wed, 26 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Construction Management Systems (CMS) Domain Corpora]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=cms-domain-corpora</link>
    <guid isPermaLink="false">datasets:cms-domain-corpora:2025-11-26</guid>
    <pubDate>Wed, 26 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[The rising demand for automated methods in the Construction Management Systems (CMS) sector highlights opportunities for the Transformer architecture, which enables pre-training Deep Learning models on large, unlabeled datasets for Natural Language Processing (NLP) tasks, outperforming traditional Recurrent Neural Network models. However, their potential in the CMS domain remains underexplored. Therefore, this research produced the first CMS domain corpora from academic papers and introduced an end-to-end pipeline for pre-training and fine-tuning domain-specific Pre-trained Language Models. Four corpora were constructed and transfer learning was employed to pre-train BERT and RoBERTa using the corpora. The best-performing models were then fine-tuned and outperformed models pre-trained on general corpora. In two key NLP tasks, text classification using an infrastructure condition prediction dataset and named entity recognition using an automatic construction control dataset, domain-specific pre-training improved F1 scores by 5.9% and 8.5%, respectively. These promising results demonstrate extended applicability beyond CMS to the Architecture, Engineering, and Construction sectors.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: VideoCADFormer: A Model for Learning Long-Horizon 3D CAD UI Interactions from Video]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:VideoCAD:2025-11-26</guid>
    <pubDate>Wed, 26 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Computer-Aided Design (CAD) is a time-consuming and complex process, requiring precise, long-horizon user interactions with intricate 3D interfaces. While recent advances in AI-driven user interface (UI) agents show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, failing to capture the demands of professional engineering tools. In this work, we introduce VideoCAD, the first attempt to model UI interactions for precision engineering tasks. Specifically, VideoCAD is a large-scale synthetic dataset consisting of over 41K annotated video recordings of CAD operations, generated using an automated framework for collecting high-fidelity UI action data from human-made CAD designs. Compared to existing datasets, VideoCAD offers an order-of-magnitude increase in complexity for real-world engineering UI tasks, with time horizons up to 20x longer than those in other datasets. We show two important downstream applications of VideoCAD: (1) learning UI interactions from professional 3D CAD tools for precision tasks and (2) a visual question-answering (VQA) benchmark designed to evaluate multimodal large language models (LLMs) on spatial reasoning and video understanding. To learn the UI interactions, we propose VideoCADFormer, a state-of-the-art model for learning CAD interactions directly from video, which outperforms existing behavior cloning baselines. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of video-based UI understanding, including the need for precise action grounding, multi-modal and spatial reasoning, and long-horizon dependencies.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Fire-ART: Firefighting asset recognition dataset]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=Fire-ART</link>
    <guid isPermaLink="false">datasets:Fire-ART:2025-11-22</guid>
    <pubDate>Sat, 22 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: VTT-ConIoT: IMU Dataset for Activity Recognition of Construction Workers]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=vtt-coniot</link>
    <guid isPermaLink="false">datasets:vtt-coniot:2025-11-18</guid>
    <pubDate>Tue, 18 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Dataset for generation of LOD4 models for buildings]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=LOD4-Building-Image-Modeling</link>
    <guid isPermaLink="false">datasets:LOD4-Building-Image-Modeling:2025-11-17</guid>
    <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Automated image-based generation of finite element models for masonry buildings]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:FEM_buildings:2025-11-17</guid>
    <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[To predict the response of masonry buildings to various types of loads, engineers use finite element models, specifically solid-element and macro-element models. For predicting masonry responses to seismic events in particular, equivalent frame models—a subcategory of macro-element models—are a common choice because of their low computational cost. However, an existing bottleneck in modeling pipelines is generating the geometry of the model, which is currently a slow and laborious process that is done manually using computer-aided design tools. In this paper, we address this by automating the modelling process using recent advancements in computer vision and machine learning. We present an image-based end-to-end pipeline that automatically generates finite element meshes for solid-element and equivalent-frame models of the outer walls of free-standing historical masonry buildings. As the input, our framework requires RGB images of the buildings that are processed using structure-from-motion algorithms, which create 3D geometries, and convolutional neural networks, which segment the openings and their corners. These layers are then combined to generate level of detail models. We tested our pipeline on structures with irregular surface geometries and opening layouts. While generating the solid element mesh from the level of detail model is straightforward, generating equivalent frame models required algorithms for segmenting the façade and the meshing. Experts in the field analyzed the generated equivalent frame models and determined them to be useful for numerical modeling. These finite element geometries will be invaluable for future predictions of the seismic response of damaged and undamaged buildings. The codes and dataset are publicly available for future studies and benchmarking (https://github.com/eesd-epfl/FEM_buildings and https://doi.org/10.5281/zenodo.8094306).]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Image-based geometric digital twinning for stone masonry elements]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:stone_masonry_GDT:2025-11-17</guid>
    <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[We present an image-based pipeline for generating geometrical digital twins (GDTs) of stone masonry elements with detail down to the stone level. For this purpose, we acquire RGB images of the individual stones and of the wall during the construction phase. In our framework, we use structure from motion (SfM) to first generate 3D source and destination models, which are then registered to form the GDT through non-linear least squares and 2D point feature correspondences detected on the SfM images. This method contrasts with traditional techniques that register point clouds using 3D point descriptors. Because of the robustness of image feature descriptors, we found that using 2D instead of 3D point features facilitates the automation of the GDT generation. To benchmark our algorithm, we compared the results through an Euclidean–distance-based proposed metric with a known 3D textured model from which images were synthetically generated. We show the robustness and feasibility of our method for full size elements, wherein GDTs were generated for dry-stone and stone-mortar systems. This study allows researchers to produce accurate representations of the 3D geometry of walls built for experimental research, reducing therefore uncertainties related to the stone size, shape and arrangement to a minimum when comparing 3D numerical simulations of these walls to experimental results. Codes and data sets are publicly available (https://github.com/eesd-epfl/stone_masonry_GDT and https://doi.org/10.5281/zenodo.7266587).]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Dataset for continuity-preserving crack detection]]></title>
    <link>https://www.openconstruction.org/datasets/detail.html?id=TOPO-Loss-Crack</link>
    <guid isPermaLink="false">datasets:TOPO-Loss-Crack:2025-11-16</guid>
    <pubDate>Sun, 16 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: TOPO-Loss for continuity-preserving crack detection using deep learning]]></title>
    <link>https://www.openconstruction.org/models.html</link>
    <guid isPermaLink="false">models:topo_crack_detection:2025-11-16</guid>
    <pubDate>Sun, 16 Nov 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[We present a method for segmenting cracks in images of masonry buildings damaged by earthquakes. Existing methods of crack detection fail to preserve the continuity of cracks, and their performance deteriorates with imprecise training labels. We address these problems by adapting an approach previously proposed for reconstructing roads in aerial images, in which a Convolutional Neural Network is trained with a loss function specifically designed to encourage the continuity of thin structures and to accommodate imprecise annotations. We evaluate combinations of three loss functions (the Mean Squared Error, the Dice loss and the new connectivity-oriented loss) on two datasets using TernausNet, a deep network shown to attain state-of-the-art accuracy in crack detection. We herein show that combining these three losses significantly improves the topology of the predictions quantitatively and qualitatively. We also propose a new continuity metric, named Cracks Per Patch (CPP), and share a new dataset of images of earthquake-affected urban scenes accompanied by crack annotations. The dataset and implementations are publicly available for future studies and benchmarking (https://github.com/eesd-epfl/topo_crack_detection and https://doi.org/10.5281/zenodo.6769028).]]></description>
  </item>
  </channel>
</rss>
